# DnD-Transformer: âœ¨ A Spark of Vision-Language Intelligence

<p align="center">
<img src="./llama-dnd.png" width=40%>
<p>

</div>
<p align="center" style="font-size: larger;">
  <a href="https://arxiv.org/abs/2410.01912">A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation </a>
</p>

<p align="center">
<img src="./teaser.png" width=95%>

What's New?

1. A better AR image genenation paradigm and transformer model structure based on 2D autoregression. It generate images of higher quality without increasing computation budget.

2. A spark of vision-language intelligence for the first time, enabling unconditional rich-text image generation, outperforming diffusion models like DDPM and Stable Diffusion on dedicated rich-text image datasets, highlighting the distinct advantage of autoregressive models for multimodal modeling.
<p>


<br>


## Codes
- [ ] Codes, datasets, models would be released soon ~

## Reference

```bib
@misc{chen2024sparkvisionlanguageintelligence2dimensional,
      title={A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation}, 
      author={Liang Chen and Sinan Tan and Zefan Cai and Weichu Xie and Haozhe Zhao and Yichi Zhang and Junyang Lin and Jinze Bai and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2410.01912},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.01912}, 
}
```


